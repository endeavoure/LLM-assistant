{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_lm import GPTWrapper, construct_model, SupervisedDataset\n",
    "import transformers\n",
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Собираем\" модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, kwargs = construct_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_new_tokens': 100,\n",
       " 'num_beams': 3,\n",
       " 'early_stopping': True,\n",
       " 'no_repeat_ngram_size': 2}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подгружаем датасет для обучения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_df = pd.read_parquet('datasets/argilla_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>response-1</th>\n",
       "      <th>response-2</th>\n",
       "      <th>category</th>\n",
       "      <th>original_response</th>\n",
       "      <th>external_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is Depreciation</td>\n",
       "      <td>What is Depreciation – 10 Important Facts to K...</td>\n",
       "      <td>What is Depreciation on a Car?\\nDepreciation i...</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>Depreciation is the drop in value of an asset ...</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do you know about the city of Aberdeen in...</td>\n",
       "      <td>Aberdeen, the city in which I've lived for the...</td>\n",
       "      <td>As an AI language model, I don't have personal...</td>\n",
       "      <td>open_qa</td>\n",
       "      <td>Aberdeen is a city located in the North East o...</td>\n",
       "      <td>351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Describe thunderstorm season in the United Sta...</td>\n",
       "      <td>Describe thunderstorm season in the United Sta...</td>\n",
       "      <td>Describe thunderstorm season in the United Sta...</td>\n",
       "      <td>information_extraction</td>\n",
       "      <td>Thunderstorm season in the United States and C...</td>\n",
       "      <td>10567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When did Peloton IPO?\\nOn September 26, 2019, ...</td>\n",
       "      <td>When did Peloton IPO?\\nPeloton launched its in...</td>\n",
       "      <td>When did Peloton IPO?\\nPeloton IPO'd on May 26...</td>\n",
       "      <td>closed_qa</td>\n",
       "      <td>Peloton became a public company via an initial...</td>\n",
       "      <td>12412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the best way to answer an interview qu...</td>\n",
       "      <td>The best way to answer an interview question m...</td>\n",
       "      <td>Some of the best ways to answer an interview q...</td>\n",
       "      <td>creative_writing</td>\n",
       "      <td>The first recommended step is to ask clarifyin...</td>\n",
       "      <td>2521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7396</th>\n",
       "      <td>How do i accept the change</td>\n",
       "      <td>How do i accept the change in my life\\nAccepti...</td>\n",
       "      <td>I's a great opportunity to improve. The only t...</td>\n",
       "      <td>brainstorming</td>\n",
       "      <td>Embrace the change and see the difference</td>\n",
       "      <td>15010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7397</th>\n",
       "      <td>Extract the teams that the footballer Sócrates...</td>\n",
       "      <td>Extract the teams that the footballer Sócrates...</td>\n",
       "      <td>Extract the teams that the footballer Sócrates...</td>\n",
       "      <td>information_extraction</td>\n",
       "      <td>Brazil, Botafogo-SP, Corinthians, Fiorentina</td>\n",
       "      <td>9970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7398</th>\n",
       "      <td>Without quoting directly from the text give me...</td>\n",
       "      <td>Without quoting directly from the text give me...</td>\n",
       "      <td>Without quoting directly from the text give me...</td>\n",
       "      <td>summarization</td>\n",
       "      <td>Brendon Small is a  stand-up comedian, Creator...</td>\n",
       "      <td>14205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7399</th>\n",
       "      <td>Is Killing is Sin ? Is it ture</td>\n",
       "      <td>Is Killing is Sin ? Is it ture?\\nKilling can b...</td>\n",
       "      <td>Is Killing is Sin ? Is it ture?\\nKilling is no...</td>\n",
       "      <td>brainstorming</td>\n",
       "      <td>Killing a human being should not be sin becaus...</td>\n",
       "      <td>11253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7400</th>\n",
       "      <td>Who was Otto von Bismarck?\\nOtto, Prince of Bi...</td>\n",
       "      <td>Who was Otto von Bismarck?\\nOtto von Bismarck ...</td>\n",
       "      <td>Who was Otto von Bismarck?\\nOtto von Bismarck ...</td>\n",
       "      <td>information_extraction</td>\n",
       "      <td>Otto von Bismarck was a Prussian and German so...</td>\n",
       "      <td>12872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7401 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt  \\\n",
       "0                                  What is Depreciation   \n",
       "1     What do you know about the city of Aberdeen in...   \n",
       "2     Describe thunderstorm season in the United Sta...   \n",
       "3     When did Peloton IPO?\\nOn September 26, 2019, ...   \n",
       "4     What is the best way to answer an interview qu...   \n",
       "...                                                 ...   \n",
       "7396                         How do i accept the change   \n",
       "7397  Extract the teams that the footballer Sócrates...   \n",
       "7398  Without quoting directly from the text give me...   \n",
       "7399                     Is Killing is Sin ? Is it ture   \n",
       "7400  Who was Otto von Bismarck?\\nOtto, Prince of Bi...   \n",
       "\n",
       "                                             response-1  \\\n",
       "0     What is Depreciation – 10 Important Facts to K...   \n",
       "1     Aberdeen, the city in which I've lived for the...   \n",
       "2     Describe thunderstorm season in the United Sta...   \n",
       "3     When did Peloton IPO?\\nPeloton launched its in...   \n",
       "4     The best way to answer an interview question m...   \n",
       "...                                                 ...   \n",
       "7396  How do i accept the change in my life\\nAccepti...   \n",
       "7397  Extract the teams that the footballer Sócrates...   \n",
       "7398  Without quoting directly from the text give me...   \n",
       "7399  Is Killing is Sin ? Is it ture?\\nKilling can b...   \n",
       "7400  Who was Otto von Bismarck?\\nOtto von Bismarck ...   \n",
       "\n",
       "                                             response-2  \\\n",
       "0     What is Depreciation on a Car?\\nDepreciation i...   \n",
       "1     As an AI language model, I don't have personal...   \n",
       "2     Describe thunderstorm season in the United Sta...   \n",
       "3     When did Peloton IPO?\\nPeloton IPO'd on May 26...   \n",
       "4     Some of the best ways to answer an interview q...   \n",
       "...                                                 ...   \n",
       "7396  I's a great opportunity to improve. The only t...   \n",
       "7397  Extract the teams that the footballer Sócrates...   \n",
       "7398  Without quoting directly from the text give me...   \n",
       "7399  Is Killing is Sin ? Is it ture?\\nKilling is no...   \n",
       "7400  Who was Otto von Bismarck?\\nOtto von Bismarck ...   \n",
       "\n",
       "                    category  \\\n",
       "0                    open_qa   \n",
       "1                    open_qa   \n",
       "2     information_extraction   \n",
       "3                  closed_qa   \n",
       "4           creative_writing   \n",
       "...                      ...   \n",
       "7396           brainstorming   \n",
       "7397  information_extraction   \n",
       "7398           summarization   \n",
       "7399           brainstorming   \n",
       "7400  information_extraction   \n",
       "\n",
       "                                      original_response  external_id  \n",
       "0     Depreciation is the drop in value of an asset ...          518  \n",
       "1     Aberdeen is a city located in the North East o...          351  \n",
       "2     Thunderstorm season in the United States and C...        10567  \n",
       "3     Peloton became a public company via an initial...        12412  \n",
       "4     The first recommended step is to ask clarifyin...         2521  \n",
       "...                                                 ...          ...  \n",
       "7396          Embrace the change and see the difference        15010  \n",
       "7397       Brazil, Botafogo-SP, Corinthians, Fiorentina         9970  \n",
       "7398  Brendon Small is a  stand-up comedian, Creator...        14205  \n",
       "7399  Killing a human being should not be sin becaus...        11253  \n",
       "7400  Otto von Bismarck was a Prussian and German so...        12872  \n",
       "\n",
       "[7401 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sft_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = SupervisedDataset(\n",
    "    dataset=sft_df[:7000][['prompt', 'original_response']].values,\n",
    "    tokenizer=model.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_loader = DataLoader(\n",
    "    dataset=train_batch,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель на полученном датасете.\n",
    "P.S. писал на мак оси, поэтому device = 'mps', cuda тут не поддерживается. Если сидите с винды или линукса пропишите device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value: 3.920064926147461\n",
      "Loss value: 3.1432785987854004\n",
      "Loss value: 0.6254844069480896\n",
      "Loss value: 1.5423660278320312\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#################\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss value: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss_value\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss_value\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m model\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Desktop/NLP/mailru_llm_knyshov_alexander/lib/python3.9/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/NLP/mailru_llm_knyshov_alexander/lib/python3.9/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "device = 'mps'\n",
    "model.model.to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.model.parameters(), lr= 0.0000001)\n",
    "N_ITERATIONS = 200\n",
    "cur_iteration = 0\n",
    "loss_values = []\n",
    "\n",
    "for x in train_batch_loader:\n",
    "    if cur_iteration == N_ITERATIONS:\n",
    "      break\n",
    "\n",
    "    model.model.train()\n",
    "    #################\n",
    "    input_tokens = x['input_ids'].to(device)\n",
    "    attention_mask = x['input_att_mask'].to(device)\n",
    "    labels = x['labels'].clone().to(device)\n",
    "    out_logits = model.model(input_ids=input_tokens, attention_mask=attention_mask).logits\n",
    "\n",
    "    ### не затираем токены начала и конца, чтобы модель училась останавливаться ###\n",
    "    labels[labels == 60000] = -100\n",
    "\n",
    "    loss_value = loss(out_logits.permute(0, 2, 1), labels)\n",
    "    #################\n",
    "    print(f\"Loss value: {loss_value.item()}\")\n",
    "    loss_value.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.model.eval()\n",
    "    cur_iteration += 1\n",
    "    loss_values.append(loss_value.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняю конфиг модельки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.model.state_dict(), 'models/gpt_lm/model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assistant",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
